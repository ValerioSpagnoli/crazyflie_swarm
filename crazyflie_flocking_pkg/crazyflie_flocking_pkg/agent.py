import random
from typing import Dict
import numpy as np
from crazyflie_flocking_pkg.flocking_forces import ForcesGenerator
from crazyflie_flocking_pkg.utils.configuration import FlockingConfig
from crazyflie_flocking_pkg.utils.geometry import compute_absolute_position, point_line_distance
from crazyflie_flocking_pkg.utils.definitions import Direction, ObjectType
from crazyflie_swarm_pkg.crazyflie_state import CrazyState

UNCOMMITTED = -1

class Agent:
    def __init__(self, name: str, config: FlockingConfig):
        self.forces_gen = ForcesGenerator(config)
        self.config = config
        self.name = name
        self.option = UNCOMMITTED
        self.counter = 0
        self.n_cycles_decision = 10
        self.v_mig = np.array([0, 0, 0])

    def compute_velocity(
        self, swarm_state: Dict[str, CrazyState], swarm_agents: Dict[str, Agent], target
    ):
        """
        Computes the velocities of the drone based on the forces generated by the flocking algorithm.
        """

        self.counter += 1
        self.target = target
        state = swarm_state[self.name]
        neighbors = swarm_state - {self.name: state} # Remove self from neighbors

        self.obj_detected = []
        
        self_pos = np.array([state.x, state.y, state.z])

        if state.mr_front < 2:
            drone_obj = state.mr_front * np.array([[1], [0], [0]])
            abs_pos = compute_absolute_position(
                self_pos, drone_obj, state.roll, state.pitch, state.yaw
            )
            self.obj_detected.append([abs_pos, Direction.front])

        if state.mr_left < 2:
            drone_obj = state.mr_left * np.array([[0], [1], [0]])
            abs_pos = compute_absolute_position(
                self_pos, drone_obj, state.state.roll, state.pitch, state.yaw
            )
            self.obj_detected.append([abs_pos, Direction.left])

        if state.mr_back < 2:
            drone_obj = state.mr_back * np.array([[-1], [0], [0]])
            abs_pos = compute_absolute_position(
                self_pos, drone_obj, state.roll, state.pitch, state.yaw
            )
            self.obj_detected.append([abs_pos, Direction.back])

        if state.mr_right < 2:
            drone_obj = state.mr_right * np.array([[0], [-1], [0]])
            abs_pos = compute_absolute_position(
                self_pos, drone_obj, state.roll, state.pitch, state.yaw
            )
            self.obj_detected.append([abs_pos, Direction.right])

        self.obs_dist_dir = []

        for obj in self.obj_detected:
            isObstacle = True
            
            for state, _ in swarm_state.items():
                obj_pos = obj[0]
                pos = np.reshape(pos, (3, 1))
                dist = np.linalg.norm(obj_pos - pos)

                if dist < 0.1:
                    isObstacle = False
                    obj[2] = ObjectType.drone
                    break

                if obj_pos[2] < 0.1:
                    isObstacle = False
                    obj[2] = ObjectType.floor
                    break

            if isObstacle:
                dist = np.linalg.norm(self_pos - obj[0])
                self.obs_dist_dir.append([dist, obj[1], obj[2]])
                
        if self.counter % self.n_cycles_decision == 0:
            self.searchForCommit(neighbors)
            mig_angle = self.option * 2 * np.pi / self.config.agent.num_options
            v_mig = (
                np.array([0, 0, 0])
                if self.option == UNCOMMITTED
                else np.array([np.cos(mig_angle), np.sin(mig_angle), 0])
            )
            self.v_mig = v_mig

        forces = self.forces_gen.get_forces(
            self_pos,
            yaw,
            positions,
            self.obs_dist_dir,
            self.v_mig,
            orientations,
        )
        overall_force = np.sum(forces, axis=1)

        cosyaw = np.cos(yaw)
        sinyaw = np.sin(yaw)
        u_i = np.reshape(np.array([cosyaw, sinyaw, 0]), (3, 1))

        v, omega = self.forces_gen.compute_velocities(overall_force, u_i)

        return [v, omega, forces, self.obj_detected]

    def searchForCommit(self, neighbors: Dict[str, CrazyState]):
        
        num_options = self.config.agent.num_options
        k = self.config.agent.k
        h = self.config.agent.h

        p = random.uniform(0, 1)

        if self.option == UNCOMMITTED:
            option = random.randint(1, num_options)
            v_gamma = self.getOptionValue(option)
            P_gamma = v_gamma * k

            if p < P_gamma:
                # I have a new commitment, decided by myself
                self.option = option
                return

            for n in neighs:
                if not n.option == UNCOMMITTED:
                    v_rho = self.getOptionValue(n.option)
                    P_rho = v_rho * h

                    if p < P_gamma + P_rho:
                        # I have a new commitment, convinced by someone else
                        self.option = n.option
                        return

        else:
            v_alpha = self.getOptionValue(self.option)
            P_alpha = k / v_alpha

            neighs = neighbors  # List of Agent objects

            if p < P_alpha:
                # Autonomously abandon my commitment
                self.option = UNCOMMITTED
                return

            for n in neighs:
                if not n.option == UNCOMMITTED and not n.option == self.option:
                    v_sigma = self.getOptionValue(n.option)
                    P_sigma = v_sigma * h

                    if p < P_alpha + P_sigma:
                        # I've been convinced by someone else to abandon my commitment
                        self.option = UNCOMMITTED
                        return

            # # Aggiunta da noi, caso non abbia cambiato idea
            # if not self.option == UNCOMMITTED:
            #     new_option = random.randint(1, num_options)
            #     if new_option != self.option:
            #         new_v = self.getOptionValue(new_option)
            #         if new_v > v_alpha:
            #             # I've decided to change for a better option
            #             self.option = UNCOMMITTED
            #             return

    def getOptionValue(self, option):
        angle = option * 2 * np.pi / self.config.agent.num_options

        direction_vector = np.array([np.cos(angle), np.sin(angle), 0])

        minimum_distance = 100

        for obj in self.obj_detected:
            if not obj[2] == ObjectType.obstacle:
                continue

            obj_pos = obj[0].squeeze()
            drone_obj = obj_pos - self.pos.squeeze()

            if drone_obj @ direction_vector < 0:  # Obstacle is behind
                continue

            dist = point_line_distance(obj_pos, self.pos, direction_vector)
            if dist < minimum_distance:
                minimum_distance = dist

        drone_target = self.target - self.pos.squeeze()

        target_distance = 50

        if drone_target @ direction_vector > 0:  # Target is not behind
            dist = point_line_distance(self.target, self.pos, direction_vector)
            if dist < target_distance:
                target_distance = dist

        value = minimum_distance / 100 * (1 - target_distance / 50)
        # value = minimum_distance /100 - target_distance/50

        return value if value > 0 else 1e-5  # Avoid division by zero
